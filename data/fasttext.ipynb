{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "from news_lib.scrape_news import get_db_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import feature_extraction, linear_model, metrics, ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text to remove all non word, space characters.\n",
    "\n",
    "    Args:\n",
    "        text(str): Text to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        str: Normalized text.\n",
    "    \"\"\"\n",
    "    text = re.sub('[^0-9a-zA-Z\\.]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5484d8533bd14ce789366d9a7128c482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf71742d4914bfd9a6e14603d97dfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_db_conn() as conn:\n",
    "    qry = {\n",
    "        'text': {'$exists': True}\n",
    "    }\n",
    "#     sample=con.execute('''mycoll.aggregate([\n",
    "#     { ''$match': { a: 10 } },\n",
    "#     { ''$sample': { 'size': 1 } }\n",
    "# ])''')\n",
    "    # all_articles = list(tqdm(conn.finance.news.find(qry, {'html': 0})))\n",
    "#     all_articles = list(tqdm(conn.finance.news.find(qry, {'html': 0}).sample))\n",
    "    all_articles=list(tqdm(conn.finance.news.aggregate(\n",
    "        [\n",
    "            {'$match':{'text': {'$exists': True}}},\n",
    "            {'$sample': {'size': 200000}}\n",
    "        ],\n",
    "        allowDiskUse=True\n",
    "    )))\n",
    "    df = pd.DataFrame.from_dict(all_articles).set_index('_id')\n",
    "\n",
    "df['full_text'] = df['title'] + ' ' + df['description'] + ' ' + df['text']\n",
    "df['full_text'] = [normalize_text(x) for x in tqdm(df['full_text'])]\n",
    "df = df.sample(frac=1.0, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce258775e3db454dbc4d95e793440e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf5fbc74d6545829f25527503961f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _stats_with_example(df, column):\n",
    "    out = {}\n",
    "    for article_id, tags in tqdm(zip(df.index, df[column])):\n",
    "        for tag in tags:\n",
    "            if tag == '':\n",
    "                continue\n",
    "\n",
    "            if tag not in out:\n",
    "                out[tag] = {\n",
    "                    'count': 1,\n",
    "                    'example_url': df.loc[article_id, 'url'],\n",
    "                    'example_id': article_id\n",
    "                }\n",
    "            else:\n",
    "                out[tag]['count'] += 1\n",
    "    return out\n",
    "\n",
    "tag_stats = pd.DataFrame.from_dict(_stats_with_example(df, 'tags'), orient='index')\n",
    "keyword_stats = pd.DataFrame.from_dict(_stats_with_example(df, 'keywords'), orient='index')\n",
    "tag_stats = tag_stats.sort_values('count', ascending=False).head(3000)\n",
    "keyword_stats = keyword_stats.sort_values('count', ascending=False).head(3000)\n",
    "tag_stats.to_excel('tags_unannotated.xlsx')\n",
    "keyword_stats.to_excel('keywords_unannotated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_excel('tags.xlsx', index_col=0)\n",
    "manual = manual['Manual'].dropna().to_dict()\n",
    "manual = {k: {x.strip().replace(' ', '-') for x in v.split(',')} for k, v in manual.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manual'] = [\n",
    "    set.union(set(), *[manual.get(tag, set()) for tag in tags])\n",
    "    for tags in df['tags']\n",
    "]\n",
    "\n",
    "all_tags = sorted({y for x in df['manual'] for y in x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-a230c1e1dce8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['fasttext'] = [\n"
     ]
    }
   ],
   "source": [
    "df_small = df[df['manual'] != set()]\n",
    "\n",
    "n_train = int(0.7 * df_small.shape[0])\n",
    "\n",
    "df_small['fasttext'] = [\n",
    "    ' '.join(f'__label__{x}' for x in tags)\n",
    "    for tags in df_small['manual']\n",
    "]\n",
    "\n",
    "Y_small = np.array([\n",
    "    [tag in manual_tags for tag in all_tags]\n",
    "    for manual_tags in df_small['manual']\n",
    "])\n",
    "\n",
    "df_train = df_small.iloc[:n_train]\n",
    "df_val = df_small.iloc[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91722919"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_small['fasttext'] + ' ' + df_small['full_text']\n",
    "\n",
    "open('/tmp/news.train', 'w').write('\\n'.join(text.iloc[:n_train]))\n",
    "open('/tmp/news.valid', 'w').write('\\n'.join(text.iloc[n_train:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! bash train_fasttext.sh\n",
    "# model = fasttext.load_model('news_model_cli.ftz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(\n",
    "    input=\"/tmp/news.train\", lr=1.0, epoch=2,\n",
    "    loss='ova'\n",
    ")\n",
    "model.save_model('news_model.bin')\n",
    "model.quantize(input='news_model.bin', qnorm=True, retrain=True, epoch=1, cutoff=100000)\n",
    "model.save_model('news_model.ftz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_val_preds = model.predict(list(df_val['full_text']), k=4, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_pred_to_final(labels, probs):\n",
    "    # select top 4\n",
    "    labels = labels[:4]\n",
    "    probs = probs[:4]\n",
    "\n",
    "    return [\n",
    "        x.replace('__label__', '')\n",
    "        for x, p in zip(labels, probs)\n",
    "        if p > probs[0] / 2\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = np.zeros_like(Y_small[n_train:])\n",
    "for idx in range(Y_val_pred.shape[0]):\n",
    "    preds = ft_pred_to_final(ft_val_preds[0][idx], ft_val_preds[1][idx])\n",
    "    for lab in preds:\n",
    "        lab_idx = all_tags.index(lab)\n",
    "        Y_val_pred[idx, lab_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        agriculture       0.73      0.68      0.71      1466\n",
      "         automotive       0.77      0.69      0.72      1750\n",
      "           aviation       0.75      0.61      0.67       711\n",
      "              banks       0.73      0.55      0.63      2252\n",
      "              bonds       0.54      0.35      0.42       363\n",
      "             budget       0.65      0.44      0.53       583\n",
      "          chemicals       0.00      0.00      0.00       291\n",
      "        commodities       0.79      0.69      0.74      2962\n",
      "          companies       0.77      0.85      0.81     15577\n",
      "  consumer-durables       0.88      0.04      0.07       194\n",
      "        coronavirus       0.80      0.69      0.74      1678\n",
      "    current-affairs       0.55      0.67      0.61      8565\n",
      "        derivatives       0.86      0.68      0.76       168\n",
      "         e-commerce       0.62      0.52      0.57       468\n",
      "           earnings       0.95      0.90      0.92      5827\n",
      "            economy       0.58      0.60      0.59      4997\n",
      "         enviroment       0.33      0.03      0.06        30\n",
      "        environment       0.57      0.49      0.53       625\n",
      "  export-and-import       0.56      0.34      0.42       413\n",
      " financial-services       0.63      0.41      0.50      1312\n",
      "               fmcg       0.61      0.26      0.37       619\n",
      "              forex       0.86      0.77      0.81      1188\n",
      "               gold       0.82      0.77      0.79       623\n",
      "                gst       0.64      0.29      0.40       327\n",
      "         healthcare       0.54      0.36      0.43       597\n",
      "         income-tax       0.52      0.15      0.24       169\n",
      "              infra       0.62      0.42      0.50      1819\n",
      "        it-services       0.66      0.42      0.51       706\n",
      "               jobs       0.51      0.39      0.44       792\n",
      "              legal       0.56      0.48      0.52       917\n",
      "logistics-transport       0.72      0.64      0.68      1445\n",
      "          marketing       0.50      0.27      0.35       202\n",
      "            markets       0.71      0.66      0.68      5365\n",
      "              media       0.56      0.38      0.46       460\n",
      "             metals       0.69      0.46      0.55       929\n",
      "             mining       0.62      0.39      0.48       330\n",
      "      miscellaneous       0.57      0.31      0.40       503\n",
      "       mutual-funds       0.79      0.67      0.73       443\n",
      "                oil       0.70      0.52      0.60      1202\n",
      "   personal-finance       0.44      0.10      0.16        79\n",
      "             pharma       0.74      0.49      0.59       818\n",
      "           politics       0.70      0.76      0.73      6020\n",
      "              power       0.66      0.43      0.52       872\n",
      "      private-banks       0.77      0.38      0.51       844\n",
      "          psu-banks       0.65      0.32      0.43       744\n",
      "                rbi       0.70      0.37      0.49       803\n",
      "        real-estate       0.68      0.57      0.62       703\n",
      "    recommendations       0.89      0.77      0.82      1821\n",
      "          regulator       0.67      0.44      0.53      1785\n",
      "             sports       0.76      0.82      0.79       668\n",
      "           startups       0.55      0.44      0.49       818\n",
      "              taxes       0.69      0.54      0.60       775\n",
      "         technology       0.65      0.68      0.67      3743\n",
      "              telco       0.73      0.57      0.64       790\n",
      "            tourism       0.70      0.17      0.28       183\n",
      "              world       0.65      0.70      0.68      5418\n",
      "\n",
      "          micro avg       0.70      0.66      0.68     95752\n",
      "          macro avg       0.66      0.49      0.54     95752\n",
      "       weighted avg       0.70      0.66      0.67     95752\n",
      "        samples avg       0.73      0.72      0.68     95752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasank/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_small[n_train:], Y_val_pred, target_names=all_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model('news_model.ftz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with get_db_conn() as conn:\n",
    "    qry = {\n",
    "        'text': {'$exists': True},\n",
    "        'predicted_tags': {'$exists': False},\n",
    "        'date': {'$gt': datetime(2020, 6, 1)}\n",
    "    }\n",
    "    all_articles = list(tqdm(conn.finance.news.find(qry, {'html': 0})))\n",
    "    df_update = pd.DataFrame.from_dict(all_articles).set_index('_id')\n",
    "\n",
    "df_update['full_text'] = df_update['title'] + ' ' + df_update['description'] + ' ' + df_update['text']\n",
    "df_update['full_text'] = [normalize_text(x) for x in tqdm(df_update['full_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_preds = model.predict(list(df_update['full_text']), k=4, threshold=0.1)\n",
    "df_update['ft_preds'] = [\n",
    "    ft_pred_to_final(ft_preds[0][idx], ft_preds[1][idx])\n",
    "    for idx in range(df_update.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_conn() as conn:\n",
    "    for article_id, ft_pred in tqdm(zip(df_update.index, df_update['ft_preds']), total=len(df_update)):\n",
    "        conn.finance.news.update_one(\n",
    "            {'_id': article_id},\n",
    "            {'$set': {'predicted_tags': ft_pred}}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_full_text = df_update.iloc[0]['full_text']\n",
    "model.predict(example_full_text, 4, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=stopwords.words(\"english\"), max_features=10000\n",
    ")\n",
    "tfidf.fit(df['full_text'].iloc[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_val_pred = clf.predict(X_val)\n",
    "labels = sorted(df_val['category'].unique())\n",
    "\n",
    "conf = metrics.confusion_matrix(\n",
    "    df_val['category'], clf_val_pred, labels=labels, \n",
    "    normalize='true'\n",
    ")\n",
    "\n",
    "print(metrics.classification_report(df_val['category'], clf_val_pred))\n",
    "\n",
    "conf = pd.DataFrame(conf, index=labels, columns=labels)\n",
    "plt.figure(figsize = (10*1.6,10))\n",
    "sns.heatmap(conf.round(2) * 100, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftr_names = tfidf.get_feature_names()\n",
    "\n",
    "# means = np.array(X_train.mean(axis=0))\n",
    "# coefs = clf.coef_ / (means ** 0.5)\n",
    "\n",
    "# for idx, class_ in enumerate(clf.classes_):\n",
    "#     top_coefs = np.argsort(-np.abs(coefs[idx]))\n",
    "#     print(class_)\n",
    "#     for coef_idx in top_coefs[:20]:\n",
    "#         print(coef_idx, ftr_names[coef_idx], round(coefs[idx, coef_idx]))\n",
    "        \n",
    "#     print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('/tmp/news.unsup', 'w').write('\\n'.join(df.sort_values('date', ascending=False)['full_text'].iloc[:10000]))\n",
    "\n",
    "model_emebds = fasttext.train_unsupervised(\n",
    "    input=\"/tmp/news.unsup\",\n",
    "    dim=300,\n",
    "    wordNgrams=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_conn() as conn:\n",
    "    qry = {\n",
    "        'text': {'$exists': True},\n",
    "        'date': {\n",
    "            '$gt': datetime(2020, 6, 29),\n",
    "#             '$lt': datetime(2020, 6, 29),\n",
    "         }\n",
    "    }\n",
    "    all_articles = list(tqdm(conn.finance.news.find(qry, {'html': 0})))\n",
    "    daily_news = pd.DataFrame.from_dict(all_articles).set_index('_id')\n",
    "\n",
    "daily_news['full_text'] = daily_news['title'] + ' ' + daily_news['description'] + ' ' + daily_news['text']\n",
    "daily_news['full_text'] = [normalize_text(x) for x in tqdm(daily_news['full_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_daily = np.array([model.get_sentence_vector(x) for x in daily_news['full_text']])\n",
    "X_daily_tfidf = tfidf.transform(daily_news['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "cos = metrics.pairwise.cosine_distances(X_daily, X_daily)\n",
    "graph = csr_matrix(cos < 0.05)\n",
    "\n",
    "n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "comps, counts = np.unique(labels, return_counts=True)\n",
    "for x in comps[counts > 1]:\n",
    "    print(np.where([labels == x])[1], daily_news.iloc[labels == x]['title'].to_list())\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import cluster\n",
    "# dbscan = cluster.DBSCAN(eps=0.03, metric='cosine', min_samples=2)\n",
    "# pred = dbscan.fit_predict(X_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x in range(pred.max()):\n",
    "#     print(daily_news.iloc[pred == x]['title'].to_list(), len(pred[pred==x]))\n",
    "#     print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = metrics.pairwise.cosine_distances(X_daily, X_daily)\n",
    "cos_tfidf = metrics.pairwise.cosine_distances(X_daily_tfidf, X_daily_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(cos[cos < 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(np.sort(cos, axis=1)[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in zip(*np.where(cos < 0.05)):\n",
    "#     if x != y:\n",
    "#         print(daily_news.iloc[x].title, daily_news.iloc[y].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 660#np.random.choice(X_daily.shape[0])\n",
    "print(n, daily_news.iloc[n].title, daily_news.iloc[n].website)\n",
    "for i in np.argsort(cos[n])[1:10]:\n",
    "    print(i, daily_news.iloc[i].title, daily_news.iloc[i].website, cos[n, i], cos_tfidf[n, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
