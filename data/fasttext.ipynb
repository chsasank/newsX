{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "from news_lib.scrape_news import get_db_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import feature_extraction, linear_model, metrics, ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text to remove all non word, space characters.\n",
    "\n",
    "    Args:\n",
    "        text(str): Text to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        str: Normalized text.\n",
    "    \"\"\"\n",
    "    text = re.sub('[^0-9a-zA-Z\\.]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc21eb95c60f4520b78e20869017d30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26327e725f6148f69bea9986d4a5a0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_db_conn() as conn:\n",
    "    all_articles=list(tqdm(conn.finance.news.aggregate(\n",
    "        [\n",
    "            {'$match':{'tags': {'$exists': True}}},\n",
    "            {'$project': {'text': 0}},\n",
    "            {'$sample': {'size': 1000000}}\n",
    "        ],\n",
    "        allowDiskUse=True\n",
    "    )))\n",
    "    df = pd.DataFrame.from_dict(all_articles).set_index('_id')\n",
    "\n",
    "df['full_text'] = df['title'] + ' ' + df['description'] # + ' ' + df['text']\n",
    "df['full_text'] = [normalize_text(x) for x in tqdm(df['full_text'])]\n",
    "df = df.sample(frac=1.0, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d565afd9847c4b76b5e860fa13583996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32a11d4204b426aa817639485630ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _stats_with_example(df, column):\n",
    "    out = {}\n",
    "    for article_id, tags in tqdm(zip(df.index, df[column])):\n",
    "        for tag in tags:\n",
    "            if tag == '':\n",
    "                continue\n",
    "\n",
    "            if tag not in out:\n",
    "                out[tag] = {\n",
    "                    'count': 1,\n",
    "                    'example_url': df.loc[article_id, 'url'],\n",
    "                    'example_id': article_id\n",
    "                }\n",
    "            else:\n",
    "                out[tag]['count'] += 1\n",
    "    return out\n",
    "\n",
    "tag_stats = pd.DataFrame.from_dict(_stats_with_example(df, 'tags'), orient='index')\n",
    "keyword_stats = pd.DataFrame.from_dict(_stats_with_example(df, 'keywords'), orient='index')\n",
    "tag_stats = tag_stats.sort_values('count', ascending=False).head(3000)\n",
    "keyword_stats = keyword_stats.sort_values('count', ascending=False).head(3000)\n",
    "tag_stats.to_excel('tags_unannotated.xlsx')\n",
    "keyword_stats.to_excel('keywords_unannotated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_excel('tags.xlsx', index_col=0)\n",
    "manual = manual['Manual'].dropna().to_dict()\n",
    "manual = {k: {x.strip().replace(' ', '-') for x in v.split(',')} for k, v in manual.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manual'] = [\n",
    "    set.union(set(), *[manual.get(tag, set()) for tag in tags])\n",
    "    for tags in df['tags']\n",
    "]\n",
    "\n",
    "all_tags = sorted({y for x in df['manual'] for y in x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-a230c1e1dce8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['fasttext'] = [\n"
     ]
    }
   ],
   "source": [
    "df_small = df[df['manual'] != set()]\n",
    "\n",
    "n_train = int(0.7 * df_small.shape[0])\n",
    "\n",
    "df_small['fasttext'] = [\n",
    "    ' '.join(f'__label__{x}' for x in tags)\n",
    "    for tags in df_small['manual']\n",
    "]\n",
    "\n",
    "Y_small = np.array([\n",
    "    [tag in manual_tags for tag in all_tags]\n",
    "    for manual_tags in df_small['manual']\n",
    "])\n",
    "\n",
    "df_train = df_small.iloc[:n_train]\n",
    "df_val = df_small.iloc[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56586589"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_small['fasttext'] + ' ' + df_small['full_text']\n",
    "\n",
    "open('/tmp/news.train', 'w').write('\\n'.join(text.iloc[:n_train]))\n",
    "open('/tmp/news.valid', 'w').write('\\n'.join(text.iloc[n_train:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! bash train_fasttext.sh\n",
    "# model = fasttext.load_model('news_model_cli.ftz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(\n",
    "    input=\"/tmp/news.train\", lr=1.0, epoch=2,\n",
    "    loss='ova'\n",
    ")\n",
    "# model.save_model('news_model.bin')\n",
    "# model.quantize(input='news_model.bin', qnorm=True, retrain=True, epoch=1, cutoff=100000)\n",
    "# model.save_model('news_model.ftz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_val_preds = model.predict(list(df_val['full_text']), k=4, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_pred_to_final(labels, probs):\n",
    "    # select top 4\n",
    "    labels = labels[:4]\n",
    "    probs = probs[:4]\n",
    "\n",
    "    return [\n",
    "        x.replace('__label__', '')\n",
    "        for x, p in zip(labels, probs)\n",
    "        if p > probs[0] / 2\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = np.zeros_like(Y_small[n_train:])\n",
    "for idx in range(Y_val_pred.shape[0]):\n",
    "    preds = ft_pred_to_final(ft_val_preds[0][idx], ft_val_preds[1][idx])\n",
    "    for lab in preds:\n",
    "        lab_idx = all_tags.index(lab)\n",
    "        Y_val_pred[idx, lab_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        agriculture       0.74      0.69      0.71      7334\n",
      "         automotive       0.76      0.68      0.72      8717\n",
      "           aviation       0.73      0.64      0.69      3558\n",
      "              banks       0.71      0.57      0.63     11238\n",
      "              bonds       0.50      0.33      0.40      1827\n",
      "             budget       0.66      0.50      0.57      3108\n",
      "          chemicals       0.58      0.31      0.40      1216\n",
      "        commodities       0.79      0.72      0.76     14900\n",
      "          companies       0.75      0.85      0.80     77166\n",
      "  consumer-durables       0.58      0.36      0.44       905\n",
      "        coronavirus       0.78      0.69      0.73      8489\n",
      "    current-affairs       0.56      0.67      0.61     42784\n",
      "        derivatives       0.82      0.76      0.79       842\n",
      "         e-commerce       0.64      0.50      0.56      2581\n",
      "           earnings       0.93      0.89      0.91     28773\n",
      "            economy       0.57      0.57      0.57     25282\n",
      "         enviroment       0.39      0.38      0.38       149\n",
      "        environment       0.58      0.41      0.48      3171\n",
      "  export-and-import       0.50      0.38      0.43      2051\n",
      " financial-services       0.65      0.44      0.53      6570\n",
      "               fmcg       0.66      0.40      0.50      3003\n",
      "              forex       0.84      0.73      0.78      5812\n",
      "               gold       0.82      0.74      0.78      3109\n",
      "                gst       0.67      0.43      0.52      1695\n",
      "         healthcare       0.52      0.39      0.45      3098\n",
      "         income-tax       0.54      0.32      0.40       900\n",
      "              infra       0.63      0.46      0.53      9271\n",
      "        it-services       0.72      0.45      0.56      3473\n",
      "               jobs       0.47      0.40      0.43      4025\n",
      "              legal       0.54      0.45      0.49      4698\n",
      "logistics-transport       0.68      0.63      0.65      6988\n",
      "          marketing       0.41      0.31      0.36      1193\n",
      "            markets       0.69      0.65      0.67     27004\n",
      "              media       0.56      0.48      0.52      2298\n",
      "             metals       0.71      0.51      0.60      4810\n",
      "             mining       0.65      0.51      0.57      1742\n",
      "      miscellaneous       0.59      0.29      0.39      2494\n",
      "       mutual-funds       0.76      0.69      0.73      2449\n",
      "                oil       0.69      0.53      0.60      5756\n",
      "   personal-finance       0.40      0.17      0.24       403\n",
      "             pharma       0.70      0.54      0.61      3879\n",
      "           politics       0.72      0.72      0.72     29329\n",
      "              power       0.68      0.45      0.54      4586\n",
      "      private-banks       0.74      0.45      0.56      4228\n",
      "          psu-banks       0.69      0.42      0.52      3592\n",
      "                rbi       0.68      0.47      0.56      4100\n",
      "        real-estate       0.67      0.56      0.61      3384\n",
      "    recommendations       0.90      0.80      0.85      9308\n",
      "          regulator       0.64      0.47      0.54      9092\n",
      "             sports       0.80      0.81      0.81      3737\n",
      "           startups       0.56      0.46      0.51      4075\n",
      "              taxes       0.68      0.58      0.63      4158\n",
      "         technology       0.67      0.66      0.66     18655\n",
      "              telco       0.75      0.62      0.68      4147\n",
      "            tourism       0.54      0.41      0.46       890\n",
      "              world       0.64      0.68      0.66     27533\n",
      "\n",
      "          micro avg       0.70      0.66      0.68    479575\n",
      "          macro avg       0.66      0.54      0.59    479575\n",
      "       weighted avg       0.70      0.66      0.67    479575\n",
      "        samples avg       0.73      0.72      0.68    479575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasank/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_small[n_train:], Y_val_pred, target_names=all_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model('news_model.ftz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with get_db_conn() as conn:\n",
    "    qry = {\n",
    "        'text': {'$exists': True},\n",
    "        'predicted_tags': {'$exists': False},\n",
    "        'date': {'$gt': datetime(2020, 6, 1)}\n",
    "    }\n",
    "    all_articles = list(tqdm(conn.finance.news.find(qry, {'html': 0})))\n",
    "    df_update = pd.DataFrame.from_dict(all_articles).set_index('_id')\n",
    "\n",
    "df_update['full_text'] = df_update['title'] + ' ' + df_update['description'] + ' ' + df_update['text']\n",
    "df_update['full_text'] = [normalize_text(x) for x in tqdm(df_update['full_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_preds = model.predict(list(df_update['full_text']), k=4, threshold=0.1)\n",
    "df_update['ft_preds'] = [\n",
    "    ft_pred_to_final(ft_preds[0][idx], ft_preds[1][idx])\n",
    "    for idx in range(df_update.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_conn() as conn:\n",
    "    for article_id, ft_pred in tqdm(zip(df_update.index, df_update['ft_preds']), total=len(df_update)):\n",
    "        conn.finance.news.update_one(\n",
    "            {'_id': article_id},\n",
    "            {'$set': {'predicted_tags': ft_pred}}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_full_text = df_update.iloc[0]['full_text']\n",
    "model.predict(example_full_text, 4, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=stopwords.words(\"english\"), max_features=10000\n",
    ")\n",
    "tfidf.fit(df['full_text'].iloc[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_val_pred = clf.predict(X_val)\n",
    "labels = sorted(df_val['category'].unique())\n",
    "\n",
    "conf = metrics.confusion_matrix(\n",
    "    df_val['category'], clf_val_pred, labels=labels, \n",
    "    normalize='true'\n",
    ")\n",
    "\n",
    "print(metrics.classification_report(df_val['category'], clf_val_pred))\n",
    "\n",
    "conf = pd.DataFrame(conf, index=labels, columns=labels)\n",
    "plt.figure(figsize = (10*1.6,10))\n",
    "sns.heatmap(conf.round(2) * 100, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftr_names = tfidf.get_feature_names()\n",
    "\n",
    "# means = np.array(X_train.mean(axis=0))\n",
    "# coefs = clf.coef_ / (means ** 0.5)\n",
    "\n",
    "# for idx, class_ in enumerate(clf.classes_):\n",
    "#     top_coefs = np.argsort(-np.abs(coefs[idx]))\n",
    "#     print(class_)\n",
    "#     for coef_idx in top_coefs[:20]:\n",
    "#         print(coef_idx, ftr_names[coef_idx], round(coefs[idx, coef_idx]))\n",
    "        \n",
    "#     print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('/tmp/news.unsup', 'w').write('\\n'.join(df.sort_values('date', ascending=False)['full_text'].iloc[:10000]))\n",
    "\n",
    "model_emebds = fasttext.train_unsupervised(\n",
    "    input=\"/tmp/news.unsup\",\n",
    "    dim=300,\n",
    "    wordNgrams=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_conn() as conn:\n",
    "    qry = {\n",
    "        'text': {'$exists': True},\n",
    "        'date': {\n",
    "            '$gt': datetime(2020, 6, 29),\n",
    "#             '$lt': datetime(2020, 6, 29),\n",
    "         }\n",
    "    }\n",
    "    all_articles = list(tqdm(conn.finance.news.find(qry, {'html': 0})))\n",
    "    daily_news = pd.DataFrame.from_dict(all_articles).set_index('_id')\n",
    "\n",
    "daily_news['full_text'] = daily_news['title'] + ' ' + daily_news['description'] + ' ' + daily_news['text']\n",
    "daily_news['full_text'] = [normalize_text(x) for x in tqdm(daily_news['full_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_daily = np.array([model.get_sentence_vector(x) for x in daily_news['full_text']])\n",
    "X_daily_tfidf = tfidf.transform(daily_news['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "cos = metrics.pairwise.cosine_distances(X_daily, X_daily)\n",
    "graph = csr_matrix(cos < 0.05)\n",
    "\n",
    "n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "comps, counts = np.unique(labels, return_counts=True)\n",
    "for x in comps[counts > 1]:\n",
    "    print(np.where([labels == x])[1], daily_news.iloc[labels == x]['title'].to_list())\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import cluster\n",
    "# dbscan = cluster.DBSCAN(eps=0.03, metric='cosine', min_samples=2)\n",
    "# pred = dbscan.fit_predict(X_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x in range(pred.max()):\n",
    "#     print(daily_news.iloc[pred == x]['title'].to_list(), len(pred[pred==x]))\n",
    "#     print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = metrics.pairwise.cosine_distances(X_daily, X_daily)\n",
    "cos_tfidf = metrics.pairwise.cosine_distances(X_daily_tfidf, X_daily_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(cos[cos < 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(np.sort(cos, axis=1)[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in zip(*np.where(cos < 0.05)):\n",
    "#     if x != y:\n",
    "#         print(daily_news.iloc[x].title, daily_news.iloc[y].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 660#np.random.choice(X_daily.shape[0])\n",
    "print(n, daily_news.iloc[n].title, daily_news.iloc[n].website)\n",
    "for i in np.argsort(cos[n])[1:10]:\n",
    "    print(i, daily_news.iloc[i].title, daily_news.iloc[i].website, cos[n, i], cos_tfidf[n, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
